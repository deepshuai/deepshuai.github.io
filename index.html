<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="努力，任何时候都不会晚。">
<meta property="og:url" content="https://deepshuai.github.io/index.html">
<meta property="og:site_name" content="努力，任何时候都不会晚。">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="努力，任何时候都不会晚。">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://deepshuai.github.io/">





  <title>努力，任何时候都不会晚。</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-89140122-1', 'auto');
  ga('send', 'pageview');
</script>





</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">努力，任何时候都不会晚。</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://deepshuai.github.io/2019/03/28/论文-ShiDianNao-Shifting-Vision-Processing-Closer-to-the-Sensor/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Deepshuai">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/avatar/deepshuai.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="努力，任何时候都不会晚。">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/28/论文-ShiDianNao-Shifting-Vision-Processing-Closer-to-the-Sensor/" itemprop="url">论文-ShiDianNao: Shifting Vision Processing Closer to the Sensor</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-28T14:33:05+08:00">
                2019-03-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/硬件设计/" itemprop="url" rel="index">
                    <span itemprop="name">硬件设计</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;ShiDianNao这篇论文更像是针对具体应用场景的体系结构&amp;优化的工作，但是对加速的的设计细节介绍的最为详细，无论是访存体系还是计算单元的设计都介绍的非常的细致。<strong>文章的主要思想：利用卷集神经网络(CNNs)权值共享的特性，将CNNs模型参数整体加载到SRAM构成的高速存储里，减少DRAM访问带来的开销;同时将加速器与视频图像传感器相连，减少额外的访存操作(传统模式：先将传感器采集的数据放入DRAM，然后通知加速器进行处理，在处理的过程中还要再一次的访问DRAM获取传感器数据)。</strong></p>
<p><strong><font color="red">按照上面的思路，硬件的设计不可避免的会碰到以下问题：</font></strong><br><strong>1、SRAM被分配多大的容量？</strong> 既然要将CNNs模型参数整体加载到SRAM上，那么就会面对SRAM容量的取舍，容量大了功耗增加，芯片面积增加；容量过小，模型不能完全hold住，对计算性能带来影响。<br><strong>2、计算单元和CNNs如何映射？</strong> 最简单的方式就是每个神经元映射一个硬件的计算单元，但是CNNs模型的规模各不相同并且差别很大，在一定程度上限制了灵活性；另一种思路和之前的论文一致，采用基于时分复用的方式，执行计算和加载数据流水线的方式进行，而计算过程中是一次计算一个特定的feature map的output还是一次计算多个仍然是需要衡量的问题。<br><strong>3、Data locality是否眼进行深度的挖掘和优化？</strong> 数据局部性的优化处理也可能在一定程度上提高性能，如CNNs卷积层的计算过程中一组input neuron可能会被多个output neuron使用，所以在计算单元中引入一些本地存储可能会节省访存的开销，但同时会增加硬件设计的复杂度。<br>ShiDianNao论文最大的贡献就是对以上问题都进行了分析和处理，给出了非常精巧的设计方案。</p>
<h2 id="整体硬件架构"><a href="#整体硬件架构" class="headerlink" title="整体硬件架构"></a>整体硬件架构</h2><p>首先看一下ShiDianNao的整体硬件结构：<br><img src="/2019/03/28/论文-ShiDianNao-Shifting-Vision-Processing-Closer-to-the-Sensor/shidiannao架构.png" width="400" align="center"></p>
<p>左侧NBin/NBout/SB是SRAM快用于数据的存储，而具体每一部分的存储空间如下表所示：<br><img src="/2019/03/28/论文-ShiDianNao-Shifting-Vision-Processing-Closer-to-the-Sensor/存储容量.jpg" width="250" align="center"></p>
<font color="red">这里最要解决的是问题1，也就是SRAM分配容量的问题，SB的size为128K，对于一般的CNNs网络是远远不够的，可能结合模型压缩算法可以解决该容量的问题。</font>

<p>DianNao系列的论文均采用类似的NBin/NBout/SB分离的方式，根据CNNs计算任务的特点，NBin存储input neuron，NBout存储output Neuron，SB存储模型参数。这三类存储，要求SB能够hold住模型全部的参数，NBin/NBout能够hold住完整的inpout/output neuron。因为模型的参数会被反复的使用，存在SRAM中可以减少从DRAM中加载数据时的时间开销，而输入数据中的raw data(input image)处理一次之后不再使用，所以只需要每个网络层在计算的时候input/output neuron在SRAM中即可。</p>
<p>芯片的右侧是NFU(Neural Functional Unit)，是由若干个PE组成的$x*y$大小的计算阵列，每个PE中有一个乘法器和一个加法器、若干个寄存器、两组用于在PE阵列水平/竖直方向进行数据交互的FIFO医护辅助的控制逻辑，具体的结构如下图：<br><img src="/2019/03/28/论文-ShiDianNao-Shifting-Vision-Processing-Closer-to-the-Sensor/PE.png" width="400" align="center"><br>NFU的计算结果通过一个ALU写入到NBout中，ALU中实现并行度并不是很高的运算，如平均池化的除操作、非线性激活计算等，其中非线性激活运算采用分段函数进行插值近似，在精度损失很小的情况下获得更高的性能和功耗收益。</p>
<p>NFU的PE阵列中对PE之间的data propagation进行了支持，引入改设计的目的是为了减少PE和SRAM之间的通信。对于卷积运算，同一个feature map的不同output neuron，stride没有超出kernel size的情况下，输入数据是由于部分是重复的，而PE间的data propagation引入就是为了将不同output neuron之间重复的那部分input neuron利用起来，从而减少SRAM访问的频率，可以很大程度上节省带宽，降低功耗，提升性能。其具体的收益如下图所示：<br><img src="/2019/03/28/论文-ShiDianNao-Shifting-Vision-Processing-Closer-to-the-Sensor/pedata.png" width="400" align="center"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://deepshuai.github.io/2019/03/25/论文-DaDianNao-A-Machine-Learning-Supercomputer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Deepshuai">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/avatar/deepshuai.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="努力，任何时候都不会晚。">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/25/论文-DaDianNao-A-Machine-Learning-Supercomputer/" itemprop="url">论文-DaDianNao: A Machine-Learning Supercomputer</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-25T21:57:23+08:00">
                2019-03-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/硬件设计/" itemprop="url" rel="index">
                    <span itemprop="name">硬件设计</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;之前的DianNao论文可以看作是硬件设计的基础，在此之上，对深度学习芯片所面对的应用场景进行了更加细致的划分。于是就有了面向服务器端的高性能计算架构DaDianNao，面向边缘端设备应用场景的ShiDianNao，面向更加泛化的机器学习算法的PuDianNao以及面向更加广泛的机器学习加速器的combricon指令集架构。</p>
<p>DaDianNao是一个多片的硬件系统，考虑到CNNs/DNNs和通用的工作负载所面临的存储墙的情况并不相同，它们虽然占用的存储空间很大，但是并没有超出多片系统的存储能力，也就是说可以考虑将数据分布在多片系统之上进行分布式的处理，可以充分的利用片上的高带宽和避免片外的低带宽，使大规模的网络模型可以更加高效的运行。</p>
<h2 id="整体硬件架构"><a href="#整体硬件架构" class="headerlink" title="整体硬件架构"></a>整体硬件架构</h2><p>DaDianNao可以看作是在DianNao基础之上的扩展，下图所示是DianNao的架构，<br><img src="/2019/03/25/论文-DaDianNao-A-Machine-Learning-Supercomputer/DianNao架构.png" width="400" align="center"></p>
<h3 id="单个DaDianNao结构的设计"><a href="#单个DaDianNao结构的设计" class="headerlink" title="单个DaDianNao结构的设计"></a>单个DaDianNao结构的设计</h3><p>DaDianNao的主要区别在于针对存储神经网络输入和输出数据的NBin和NBout，存储神经连接参数的SB的组织形式以及核心计算单元NFU的数据交互方式进行了针对大尺寸模型的考量，而其中最为重要的就是访存体系的设计思想和细节，DaDianDao芯片的访存体系的高层次设计图如下：<br><img src="/2019/03/25/论文-DaDianNao-A-Machine-Learning-Supercomputer/DaDianNao高层次结构.png" width="600" align="center"><br>左图是芯片的高层次图，每个芯片由16个tile组成，右图是单个tile的结构图。每个tile内部是一个NFU搭配四个存储SB的eDRAM bank组成，而NBin和NBout则是对应与左图eDRAM router所连接的两条灰色的额eDRAM bank。不难发现，在DaDianNao中SB是采用分布式的方式存储的，之所以采用这种方式，可能的理解如下：<br><strong>a、eDRAM虽然相对于DRAM的延迟显著减小，但是其本质仍然是DRAM，存在着漏电的效应，需要周期性的充电刷新，并且刷新的频率相对于DRAM可能会更高，这可能会对访存的性能带来一定的影响，通过拆分SB存储，可以在一定程度上减小周期性的刷新带来的影响。</strong><br><strong>b、将SB拆分，放在每个NFU周围，这样距离计算单元更近，这样在执行具体的计算的时候，访存的时延更小，性能更高。</strong></p>
<p><font color="red">DaDianNao相对于DianNao有一个比较明显的改变就是NBin/NBout/SB由原来的SDRAM存储改为eDRAM的存储介质，其只要原因如下：</font><br><img src="/2019/03/25/论文-DaDianNao-A-Machine-Learning-Supercomputer/DRAM.jpg" width="400" align="center"><br>由上表可以看出，使用SRAM在一定程度上可以缩小延迟，但是其需要的面积太大，这尤其是在高性能计算芯片中面积增加程度很高，成本散热以及功耗都是很难处理的问题，选用eDRAM也是在存储密度/访存延迟/功耗之间最为适宜的权衡。</p>
<p>每个tile内部的NFU内部结构如图所示：<br><img src="/2019/03/25/论文-DaDianNao-A-Machine-Learning-Supercomputer/DADIANNAONFU.png" width="400" align="center"><br>图中详细描绘了NFU流水线的每个阶段与NBin/NBout/SB的交互，针对不同的网络层，根据其存储和计算的特性，其流水线的工作模式如下图所示：<br><img src="/2019/03/25/论文-DaDianNao-A-Machine-Learning-Supercomputer/pipeline.png" width="600" align="center"><br>其中的红色部分The eDram表示的就是SB存储，</p>
<p>&emsp;&emsp;以上是单个DaDianNao芯片的设计，由下表可知，单个DaDianNao芯片中用于NBin/NBout的central eDRAM的存储容量为4MB，每个tile中用于SB的eDRAM的容量是2MB，每个芯片由16个tile组成，所以单个芯片的eDRAM的总容量是$4+2*16=36$MB，仅仅单片的容量是无法对大模型的网络进行高性能的计算的，所以论文又提出了多片互连的架构。<br><img src="/2019/03/25/论文-DaDianNao-A-Machine-Learning-Supercomputer/容量.png" width="400" align="center"></p>
<h3 id="多个DaDianNao结构的互连"><a href="#多个DaDianNao结构的互连" class="headerlink" title="多个DaDianNao结构的互连"></a>多个DaDianNao结构的互连</h3><p>DaDianNao的多片互连并不是定制的设计，而是直接使用现成的技术，即HyperTransport 2.0通信IP，在每个DaDianNao芯片的上下左右四周提供四组HT 2.0的通信通道，每个通道的通信带宽在in/out方向分别达到6.6GB/s，由于相互之间数据的交换，支持全双工通信且延迟为80ns。</p>
<p>多片互连的结构可以支持大尺寸的网路模型，不同的模型在多片的模式下通信的数据量存在着较大的差异：<br><img src="/2019/03/25/论文-DaDianNao-A-Machine-Learning-Supercomputer/差异.png" width="600" align="center"></p>
<h2 id="相对于GPU的对比实验"><a href="#相对于GPU的对比实验" class="headerlink" title="相对于GPU的对比实验"></a>相对于GPU的对比实验</h2><p>下图是对模型训练的过程中不同的网络层在多片硬件上相对于GPU的加速的效果：<br><img src="/2019/03/25/论文-DaDianNao-A-Machine-Learning-Supercomputer/trainingsp.png" width="400" align="center"></p>
<p>下图是对模型前向过程中不同的网络层在多片硬件上相对于GPU的能耗比：<br><img src="/2019/03/25/论文-DaDianNao-A-Machine-Learning-Supercomputer/eninference.png" width="400" align="center"></p>
<p>下图是对模型训练的过程中不同的网络层在多片硬件上相对于GPU的能耗比：<br><img src="/2019/03/25/论文-DaDianNao-A-Machine-Learning-Supercomputer/entraining.png" width="400" align="center"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://deepshuai.github.io/2019/03/21/论文-DianNao-A-Small-Footprint-High-Throughput-Accelerator-for-Ubiquitous-Machine-Learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Deepshuai">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/avatar/deepshuai.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="努力，任何时候都不会晚。">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/21/论文-DianNao-A-Small-Footprint-High-Throughput-Accelerator-for-Ubiquitous-Machine-Learning/" itemprop="url">论文-DianNao: A Small-Footprint High-Throughput Accelerator for Ubiquitous Machine-Learning</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-21T10:58:04+08:00">
                2019-03-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/硬件设计/" itemprop="url" rel="index">
                    <span itemprop="name">硬件设计</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;该论文是寒武纪团队的第一篇论文。论文结合了神经网络模型数据的局部性特点以及计算的特点，进行存储体系以及专用硬件的设计，从而获得更好的性能加速比以及计算功耗比。</p>
<p><strong>论文的主要贡献：</strong></p>
<font color="red">1、对大规模的CNNs和DNNs最先进机器学习算法的综合硬件设计；<br>2、在很小的芯片空间上实现高吞吐率和低功耗；<br>3、专注于优化访存的性能，着重解决”存储墙”的问题。</font>


<h2 id="神经网络的硬件化"><a href="#神经网络的硬件化" class="headerlink" title="神经网络的硬件化"></a>神经网络的硬件化</h2><p>&emsp;&emsp;神经网络的结构模拟人类大脑内部的神经元结构，每一个神经元有很多的突触，用于给其他的神经元来传递信息，所有神经元的信息累加，会使该神经元处于兴奋或者抑制状态。成千上万个神经元组合起来就是一个神经网络模型。如下图所示：<br><img src="/2019/03/21/论文-DianNao-A-Small-Footprint-High-Throughput-Accelerator-for-Ubiquitous-Machine-Learning/神经网络硬件化.png" width="400" align="center"><br>对于到卷积神经网络的计算，神经的突触就是就是具体的卷积运算中侧乘法步骤，而神经元就是对所有突触效果累加效果和非线性激活的处理。论文首先回顾了之前常见的全硬件实现方案(full-hardware implementation)—通常是将每个神经元都映射到具体的硬件计算单元上。这种方案虽然实现方式简洁，计算性能高，但是灵活性很差，尤其是深度学习算法快速更新，网络模型的结构以及尺寸的变化都会使该方案失效，下图是full-hardware implementationan方案的硬件关键路径的时延、芯片面积和功耗的变化趋势：<br><img src="/2019/03/21/论文-DianNao-A-Small-Footprint-High-Throughput-Accelerator-for-Ubiquitous-Machine-Learning/全硬件化功耗延迟和面积.png" width="400" align="center"></p>
<p>明显可以看到硬件对模型伸缩性的处理不理想的问题，为了解决这个问题，寒武纪团队提出DianNao的计算架构。</p>
<p>&emsp;&emsp;下图是DianNao内部的硬件结构，其中包含三个片上存储，分别是存储输入的NBin、存储输出的NBout以及存储神经网络模型参数的SB，三块存储均是基于SRAM实现，以获取低延时和低功耗的收益。片上存储和片外存储的数据交互方式通过DMA来完成，尽可能的节省通讯的时延。浅蓝色阴影部分是硬件逻辑模拟的神经网络结构，整个部分被称为NFU，是一个包含NFU-1、NFU-2、NFU-3三段的pipeline的结构。<br><img src="/2019/03/21/论文-DianNao-A-Small-Footprint-High-Throughput-Accelerator-for-Ubiquitous-Machine-Learning/DianNao加速模块.png" width="400" align="center"></p>
<p>&emsp;&emsp;<strong>NFU-1</strong>包含16个乘法单元，每个乘法单元拥有16个乘法器，因此NFU-1总共包含$16\times16=256$个乘法器，每个周期可以执行256个乘法运算； <strong>NFU-2</strong>包含16个树状的加法单元，每个加法树按照8-4-2-1个加法器的形式对数据执行加法运算；<strong>NFU-3</strong>包含16个非线性激活单元，每个激活单元对输出的数据进行非线性激活处理。对NFU逻辑结构横向观察发现，NFU的所有逻辑单元被分为16份，包含16个乘法器、$8+4+2+1=15$个加法器，一个激活单元。<br>&emsp;&emsp;整个硬件架构的核心就是三个片上存储和一个拥有三级流水的神经功能单元。根据时分复用的思想，对一个对规模的神经网络，神经网络的参数会以此加载到SB里，每层的输入数据加载到NBin中，每层的计算结果加载到NBout中，NFU提供最基础的计算逻辑(乘法、加法、非线性激活)，这种结构不会与具体的神经网络结构以及其参数规模相互绑定，相较与之前full-hardware implementation的硬件加速器设计，在结构和模型尺寸的灵活性上有很大的改进。</p>
<h2 id="优化细节"><a href="#优化细节" class="headerlink" title="优化细节"></a>优化细节</h2><h3 id="16位定点数代替32位浮点数"><a href="#16位定点数代替32位浮点数" class="headerlink" title="16位定点数代替32位浮点数"></a>16位定点数代替32位浮点数</h3><p>&emsp;&emsp;16位定点数代替32位浮点数的前提：神经网路模型的精度不能显著降低。在模型压缩和加速算法研究领域已经出现很多的研究成果，利用8-bit定点数和16-bit定点数来代替原模型32位浮点数据，并且模型的精度基本没有损失，所以，DianNao论文采用低精度的策略也是建立在算法研究的基础之上的，如下图：<br><img src="/2019/03/21/论文-DianNao-A-Small-Footprint-High-Throughput-Accelerator-for-Ubiquitous-Machine-Learning/mnist精度.png" width="400" align="center"><br>mnist数据集(一个较小的手写数字分类的数据集)上的神经网络在16-bit定点数和32位浮点数时对应的分类错误率，相差很小，基本可以忽略。</p>
<p>而下图是两种精度下芯片的面积和功耗比较：<br><img src="/2019/03/21/论文-DianNao-A-Small-Footprint-High-Throughput-Accelerator-for-Ubiquitous-Machine-Learning/面积和功耗.png" width="400" align="center"><br>在很少的精度损失的前提下，芯片的面积将为原来的1/6，而功耗也仅仅为1/7不到，这一种很好的权衡策略。</p>
<h3 id="NBin-NBout-SB存储模块分离"><a href="#NBin-NBout-SB存储模块分离" class="headerlink" title="NBin/NBout/SB存储模块分离"></a>NBin/NBout/SB存储模块分离</h3><p>虽然三个存储模块都是片上的SRAM，但是三个模块是彼此独立的，其主要原因是不同的访存带宽，NBin/NBout的访存单位是向量，SB的访存单位是矩阵，不同的访存宽度在功耗上有很明显的差异：<br><img src="/2019/03/21/论文-DianNao-A-Small-Footprint-High-Throughput-Accelerator-for-Ubiquitous-Machine-Learning/访存宽度和功耗.png" width="400" align="center"><br>拆分成不同的模块，可以在性能和功耗之间找到很好的平衡点，可以理解层对内存带宽采用更加细粒度的分析。而将NBin和NBout也进行拆分主要是为了降低数据相关性，NBin和NBout类似于cache用来缓存模型计算过程中数据的输入和输出，两种数据访问的模式可能不同，将其放入不同的SRAM中，减少了数据相关性，在一定程度上提升了性能，简化逻辑的同时降低了功耗。</p>
<h3 id="考虑NBin和SB数据局部性"><a href="#考虑NBin和SB数据局部性" class="headerlink" title="考虑NBin和SB数据局部性"></a>考虑NBin和SB数据局部性</h3><p>该思想与流水线设计思想一致，就是将数据的加载和计算过程进行overlap，当对当前数据进行计算的同时，通过DMA对下一组数据的加载，该功能的实现需要比较精细的逻辑同步，同时要求NBin/SB满足双端口的访问，这在一定程度上会增加功耗。</p>
<h3 id="考虑NBout数据局部性"><a href="#考虑NBout数据局部性" class="headerlink" title="考虑NBout数据局部性"></a>考虑NBout数据局部性</h3><p>在NFU中增加专用的寄存器，如果计算数据的规模比较大，一次NBin只能加载部分的数据，那么计算的结果也就是最终结果的一部分，这时增加的寄存器暂存partial的结果，用于快速的结果组合，减少计算结果片外写入和片内读入的开销，在一定程度上有性能的提升。</p>
<h2 id="实验及结果分析"><a href="#实验及结果分析" class="headerlink" title="实验及结果分析"></a>实验及结果分析</h2><p>对多种尺寸的卷积层、全连接层和池化层进行实验分析，实验的baseline是CPU的ISMD计算，该设计在芯片面积，功耗以及计算时延方面都有数量级的提升，具体的结果参考论文<font color="ff00"><a href="http://boogie.is.titech.ac.jp/lecture/lecture-wiki/index.php?plugin=attach&amp;refer=hpc2015&amp;openfile=DianNao.pdf" target="_blank" rel="noopener">DianNao: A Small-Footprint High-Throughput Accelerator for Ubiquitous</a></font></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://deepshuai.github.io/2019/03/18/第一篇博客/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Deepshuai">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/avatar/deepshuai.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="努力，任何时候都不会晚。">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/18/第一篇博客/" itemprop="url">中科院计算所寒武纪团队DianNao系列论文导读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-18T15:57:58+08:00">
                2019-03-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/硬件设计/" itemprop="url" rel="index">
                    <span itemprop="name">硬件设计</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;中科院计算所的这几篇DianNao系列论文引发了专用深度学习加速器研究和应用的热潮，后续的博客将会读每一篇论文进行阅读和分析，在每一篇的论文阅读之前，我们先梳理一下寒武纪芯片DianNao的整体项目。</p>
<h2 id="DianNao项目之前："><a href="#DianNao项目之前：" class="headerlink" title="DianNao项目之前："></a>DianNao项目之前：</h2><p>&emsp;&emsp;2010年，Temam教授在ISCA的主题报告上提到，机器学习硬件加速器是处理器微结构领域极有吸引力的一个发展方向，是处理器技术、应用和机器学习发展的大势所趋。在2012年的ISCA上，Temam教授提出了第一个机器学习加速器设计，表明在以神经网络为基础的一大类应用上是可以以很小的面积和功耗获得高性能的。但此工作的主要局限性在于其内存带宽。</p>
<h2 id="DianNao项目："><a href="#DianNao项目：" class="headerlink" title="DianNao项目："></a>DianNao项目：</h2><p>&emsp;&emsp;DianNao学术项目的目标是面向机器学习研究加速器架构。本项目是中科院计算所的陈云霁教授和法国Inria的Olivier Temam间的一个学术合作项目，双方为此设立了联合实验室。</p>
<p>&emsp;&emsp;Temam教授和陈教授的合作始于第一个加速器，名为<font color="ff00"><a href="http://boogie.is.titech.ac.jp/lecture/lecture-wiki/index.php?plugin=attach&amp;refer=hpc2015&amp;openfile=DianNao.pdf" target="_blank" rel="noopener">DianNao</a></font>（这也是DianNao家族的第一个成员）。DianNao在ISCA-2012加速器的基础上增加了局部存储，使其可以捕捉深度神经网路的数据局部性并由此克服内存带宽的限制。DianNao加速器的设计发表于ASPLOS-2014，获得了该会议的最佳论文奖。</p>
<p>&emsp;&emsp;DianNao家族的第二个加速器是DianNao的多片版本，有两个主要的设计目标：一是揭示神经网络层的可分特性使得加速器可具备极好的可扩展性，二是聚集足够多的片上存储来将整个机器学习模型都放在片上，从而克服内存带宽的限制。这个被称为<font color="ff00"><a href="http://novel.ict.ac.cn/ychen/pdf/DaDianNao.pdf" target="_blank" rel="noopener">DaDianNao</a></font>的设计发表在MICRO-2014上，获得了该会议的最佳论文奖。</p>
<p>&emsp;&emsp;作为克服嵌入式应用中内存带宽限制的另一种方法，我们揭示可以通过加速器和传感器的直连来绕过内存。我们将此思想应用于视觉传感器，从而提出了DianNao家族的第三个加速器<font color="ff00"><a href="https://dl.acm.org/citation.cfm?doid=2749469.2750389" target="_blank" rel="noopener">ShiDianNao</a></font>，发表于2015年的ISCA上。</p>
<p>&emsp;&emsp;最后，我们也揭示这类加速器的应用领域可以被拓展至多种机器学习算法，因为这些算法多具有类似的运算操作。相应的加速器设计称为<font color="#ff00"><a href="https://dl.acm.org/citation.cfm?doid=2694344.2694358" target="_blank" rel="noopener">PuDianNao</a></font>（DianNao家族的第四个以及最后一个成员），发表于ASPLOS-2015。</p>
<h2 id="DianNao项目之后"><a href="#DianNao项目之后" class="headerlink" title="DianNao项目之后"></a>DianNao项目之后</h2><p>&emsp;&emsp;陈云霁教授和他的中科院计算所团队为一大类神经网络加速器设计了一套名为<font color="ff00"><a href="https://dl.acm.org/citation.cfm?id=3001179" target="_blank" rel="noopener">Cambricon的指令集</a></font>。该指令集发表于ISCA-2016，在该会议的同行评议中获得了最高分。</p>
<p>&emsp;&emsp;同时针对深度学习模型中的稀疏化特点，又提出了一种对稀疏权重的矩阵运算加速的架构<a href="https://ieeexplore.ieee.org/document/7783723" target="_blank" rel="noopener">Cambricon-X</a>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/avatar/deepshuai.jpg" alt="Deepshuai">
            
              <p class="site-author-name" itemprop="name">Deepshuai</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Deepshuai</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
